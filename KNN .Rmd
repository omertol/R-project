---
title: "KNN"
output:
  word_document: default
  html_document: default
  pdf_document: default
date: '2022-06-06'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages, message = FALSE}
library(knitr)
library(tidyverse)
library(broom)
library(htmltools)
library(class)
```

```{r}
#Load data
list_df <- list.files("./data/spike data", pattern="*.csv", full.names=TRUE)
ldf <- lapply(list_df, read.csv)
```

```{r find wells and treatments, warning=FALSE}
if (file.exists("./data/wells and treatment.csv")){
  df <- read.csv("./data/wells and treatment.csv")
} else {
  # Load one of the data files (arbitrarily) to extract the well information chart
  df <- read.csv(file = "./data/spike data/ac div16(000)_spike_list.csv")
  
  # Find the chart in the file
  rnom <- as.numeric(which(df == "Well Information"))
  df <- fread(file = "./data/spike data/ac div16(000)_spike_list.csv", skip=rnom)
  
  
  # Select only well ID and treatment given
  df <- df[which(df$`Well Information` == "Well" | 
            df$`Well Information` == "Treatment"),]
  
  # Transpose to a longer data frame and fix labeling
  df <- data.frame(t(df[,2:ncol(df)]))
  rownames(df) <- seq(1:nrow(df))
  colnames(df) <- c("Well", "Treatment")
  
  # Filter inactive wells
  df <- df[df$Treatment != "Inactive",]
  
  # Create and save a .csv file for future use
  write.csv(df,"./data/wells and treatment.csv", row.names = FALSE)
}
```

```{r clean the data, message=FALSE}
remove_inactive <- function(df){
  df <- df[c(3,4,5)]
  df <- drop_na(df)
  #only the first 11 minutes
  df<- df %>% filter(df$Time..s.<=660) 
  df <- df[df$Electrode %like% paste(df$Well, collapse = "|"),] 
  df$Time..s. <- as.numeric(df$Time..s.)
  return(df)
}

sep_wells <- function(df){
  df <- separate(df, col = "Electrode",
           into = c("Well", "Electrode"),
           sep = "_")
  return(df)
}

ldf <- lapply(ldf, remove_inactive)
ldf <- lapply(ldf, sep_wells)
```

```{r}
df1 <- ldf[1]
ldf <- ldf[2:length(ldf)]
```

```{r}
get_df <- function(df1, df2){
  
  df1 <- df1 %>% data.frame()
  df2 <- df2 %>% data.frame() 
  
  #create one df
  tmp <- right_join(df1,df,by="Well") 
  tmp <- right_join(df2,tmp, by="Well")
  tmp[is.na(tmp)] <- 0 #replace na`s value with 0's
  tmp$n <- as.numeric(tmp$n.y - tmp$n.x)
  return(tmp[, c("Well", "n", "Treatment")])
}
pairwise_knn <- function(join_df){
  join_df <- join_df[,c("n", "Treatment")]
  ran <- sample(1:nrow(join_df), 0.8 * nrow(join_df))
  nor <-function(x) {
    return ((x -min(x))/(max(x)-min(x)))
    }
    
  ##Run normalization on first column of dataset because it is the predictor
  join_df_norm <- as.data.frame(lapply(join_df[c(1)], nor))
  train <- data.frame(join_df_norm[ran,])
  test <- data.frame(join_df_norm[-ran,])
  target<-as.factor(join_df[ran,2])
  test_category <-as.factor( join_df[-ran,2])
  
  knn_model <- knn(train=train,test=test,cl=target, k=10)
  
  ##create confusion matrix
  tab <- table(knn_model,test_category)
  ##this function divides the correct predictions by total number of predictions that tell us how accurate teh model is.
  accuracy <- function(x){
    return(sum(diag(x)/(sum(rowSums(x)))) * 100)
  }
  
  print(accuracy(tab))
}
```

```{r}
for(i in  ldf){
  join_df <- get_df(df1,i)
  df1 <- i
  pairwise_knn(join_df)
}
```
